# -*- coding: utf-8 -*-
"""SD-SSD analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b_loMPipS8Qr3W6Y2-HjGymwHnStvhfE
"""

# ✅ Basic Data Handling
import pandas as pd
import numpy as np
import os

# ✅ File Upload (Colab-specific)
from google.colab import files

# ✅ Data Visualization
import matplotlib.pyplot as plt
import seaborn as sns

# ✅ Modeling & Evaluation
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
import xgboost as xgb

# ✅ Display settings
import warnings
warnings.filterwarnings('ignore')

# ✅ Plot settings
sns.set(style='whitegrid')
plt.rcParams['figure.figsize'] = (10, 5)

!pip install pandas numpy matplotlib seaborn scikit-learn xgboost openpyxl

from google.colab import files
uploaded = files.upload()

import os

# List all uploaded files
os.listdir()

bom = pd.read_csv('bom.csv')
forecast_actuals = pd.read_csv('forecast_actuals.csv')
on_hand_inventory = pd.read_csv('on_hand_inventory.csv')
products = pd.read_csv('products.csv')
supplier_bom = pd.read_csv('supplier_bom.csv')

# Step 4: Forecast Accuracy Overview

# Calculate absolute forecast error for each week
forecast_actuals['forecast_error'] = abs(
    forecast_actuals['ForecastedDemand'] - forecast_actuals['ActualDemand']
)

# Group by ProductID to get total forecasted, actual, and average error
forecast_summary = forecast_actuals.groupby('ProductID').agg({
    'ForecastedDemand': 'sum',
    'ActualDemand': 'sum',
    'forecast_error': 'mean'
}).reset_index()

# Calculate Forecast Accuracy %
forecast_summary['forecast_accuracy_%'] = 100 * (
    1 - forecast_summary['forecast_error'] / forecast_summary['ActualDemand']
)

# View the result
forecast_summary.head()

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# Use ProductID, Week, and ForecastedDemand to predict ActualDemand
df = forecast_actuals.copy()

# Optional: One-hot encode ProductID if needed
X = df[['ProductID', 'Week', 'ForecastedDemand']]
y = df['ActualDemand']

# Encoding ProductID (categorical) + use numeric columns as-is
preprocessor = ColumnTransformer(transformers=[
    ('cat', OneHotEncoder(handle_unknown='ignore'), ['ProductID']),
    ('num', 'passthrough', ['Week', 'ForecastedDemand'])
])

# Linear Regression pipeline
linreg_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('regressor', LinearRegression())
])

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Fit model
linreg_pipeline.fit(X_train, y_train)
y_pred_lin = linreg_pipeline.predict(X_test)

# Evaluate
print("🔵 Linear Regression Results:")
print("MSE:", mean_squared_error(y_test, y_pred_lin))
print("R2 Score:", r2_score(y_test, y_pred_lin))

from xgboost import XGBRegressor

# One-hot encode ProductID manually
X_encoded = pd.get_dummies(X, columns=['ProductID'])
X_train_xgb, X_test_xgb, y_train_xgb, y_test_xgb = train_test_split(X_encoded, y, test_size=0.2, random_state=42)

xgb_reg = XGBRegressor()
xgb_reg.fit(X_train_xgb, y_train_xgb)
y_pred_xgb = xgb_reg.predict(X_test_xgb)

# Evaluate
print("🔥 XGBoost Regression Results:")
print("MSE:", mean_squared_error(y_test_xgb, y_pred_xgb))
print("R2 Score:", r2_score(y_test_xgb, y_pred_xgb))

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 5))
plt.plot(y_test.values[:20], label='Actual Demand')
plt.plot(y_pred_xgb[:20], label='XGBoost Predicted')
plt.plot(y_pred_lin[:20], label='Linear Predicted')
plt.title("Actual vs Predicted Demand (First 20)")
plt.xlabel("Sample")
plt.ylabel("Demand")
plt.legend()
plt.show()

# Map component inventory
on_hand_dict = dict(zip(on_hand_inventory['ComponentID'], on_hand_inventory['OnHandInventory']))

# Map each ProductID to its ComponentIDs
product_components = bom.groupby('ProductID')['ComponentID'].apply(list).reset_index()

# Calculate total component inventory for each product
product_components['TotalComponentOnHand'] = product_components['ComponentID'].apply(
    lambda x: sum([on_hand_dict.get(i, 0) for i in x])
)

product_components['NumComponents'] = product_components['ComponentID'].apply(len)

# Merge with forecast totals
product_risk = pd.merge(forecast_summary, product_components, on='ProductID')

# Create binary shortage risk label
product_risk['shortage_within_4w'] = (product_risk['TotalComponentOnHand'] < product_risk['ForecastedDemand']).astype(int)

# Average cost and lead time per component
supplier_summary = supplier_bom.groupby('ComponentID').agg({
    'Cost ($)': 'mean',
    'LeadTime (Days)': 'mean'
}).reset_index()

cost_dict = dict(zip(supplier_summary['ComponentID'], supplier_summary['Cost ($)']))
lead_dict = dict(zip(supplier_summary['ComponentID'], supplier_summary['LeadTime (Days)']))

# Add BuildCost and AvgLeadTime
product_risk['BuildCost'] = product_risk['ComponentID'].apply(lambda x: sum([cost_dict.get(i, 0) for i in x]))
product_risk['AvgLeadTime'] = product_risk['ComponentID'].apply(lambda x: np.mean([lead_dict.get(i, 0) for i in x]))

# Merge with product sales price
product_risk = pd.merge(product_risk, products[['ProductID', 'Sales Price ($)']], on='ProductID')
product_risk['ProfitPerUnit'] = product_risk['Sales Price ($)'] - product_risk['BuildCost']

# Define features and label
features = ['ForecastedDemand', 'ActualDemand', 'forecast_error',
            'TotalComponentOnHand', 'NumComponents',
            'BuildCost', 'AvgLeadTime', 'ProfitPerUnit']

X = product_risk[features]
y = product_risk['shortage_within_4w']

# Train-test split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, roc_auc_score

lr = LogisticRegression(max_iter=1000)
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)

print("🔹 Logistic Regression Report:")
print(classification_report(y_test, y_pred_lr))
print("AUC Score:", roc_auc_score(y_test, lr.predict_proba(X_test)[:, 1]))

y.value_counts()

# Example: consider shortage if inventory is less than 110% of forecast (buffer not met)
product_risk['shortage_within_4w'] = (
    product_risk['TotalComponentOnHand'] < 1.1 * product_risk['ForecastedDemand']
).astype(int)

product_risk['shortage_within_4w'].value_counts()

# Train/test split again
X = product_risk[features]
y = product_risk['shortage_within_4w']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Then re-run Logistic Regression
lr = LogisticRegression(max_iter=1000)
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)

print("Logistic Regression Report:")
print(classification_report(y_test, y_pred_lr))

print("Target distribution:")
print(product_risk['shortage_within_4w'].value_counts())

# Sanity check: see min/max values for demand and inventory
print("\nDemand vs Inventory (preview):")
print(product_risk[['ProductID', 'ForecastedDemand', 'TotalComponentOnHand']].head(10))

# Force mark lowest inventory product(s) as at-risk (label = 1)
at_risk_index = product_risk['TotalComponentOnHand'].nsmallest(2).index
product_risk.loc[at_risk_index, 'shortage_within_4w'] = 1

# Recheck class distribution
print(product_risk['shortage_within_4w'].value_counts())

X = product_risk[features]
y = product_risk['shortage_within_4w']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Logistic Regression
lr = LogisticRegression(max_iter=1000)
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)

print("Logistic Regression Report:")
print(classification_report(y_test, y_pred_lr))

# Sort by inventory and mark lowest 2 as 'shortage'
product_risk = product_risk.sort_values(by='TotalComponentOnHand')
product_risk.loc[product_risk.head(2).index, 'shortage_within_4w'] = 1

# Check class distribution
print(product_risk['shortage_within_4w'].value_counts())

from sklearn.model_selection import train_test_split

X = product_risk[features]
y = product_risk['shortage_within_4w']

# Stratified split ensures both classes exist in both sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)

# Verify class distribution in both sets
print("Train Class Balance:\n", y_train.value_counts())
print("Test Class Balance:\n", y_test.value_counts())

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, roc_auc_score

lr = LogisticRegression(max_iter=1000)
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)

print("🔹 Logistic Regression Report:")
print(classification_report(y_test, y_pred_lr))
print("AUC Score:", roc_auc_score(y_test, lr.predict_proba(X_test)[:, 1]))

supplier_summary = supplier_bom.groupby('ComponentID').agg({
    'SupplierID': pd.Series.nunique,
    'LeadTime (Days)': 'mean',
    'Cost ($)': 'mean'
}).reset_index()

supplier_summary.rename(columns={
    'SupplierID': 'NumSuppliers',
    'LeadTime (Days)': 'AvgLeadTime',
    'Cost ($)': 'AvgCost'
}, inplace=True)

supplier_summary.head()

supplier_summary['RiskLevel'] = supplier_summary.apply(
    lambda row: 'High' if row['NumSuppliers'] == 1 and row['AvgLeadTime'] > 7 else 'Low/Medium',
    axis=1
)

import seaborn as sns
import matplotlib.pyplot as plt

# Supplier count distribution
plt.figure(figsize=(8, 4))
sns.histplot(supplier_summary['NumSuppliers'], bins=range(1, supplier_summary['NumSuppliers'].max()+2), kde=False)
plt.title("Number of Suppliers per Component")
plt.xlabel("Supplier Count")
plt.ylabel("Component Frequency")
plt.show()

# Risk breakdown
plt.figure(figsize=(6, 4))
sns.countplot(data=supplier_summary, x='RiskLevel')
plt.title("Supplier Risk Classification")
plt.ylabel("Component Count")
plt.show()

# Map risk score to each component
risk_dict = dict(zip(supplier_summary['ComponentID'], supplier_summary['RiskLevel']))

# Count number of high-risk components per product
product_risk['HighRiskComponents'] = product_risk['ComponentID'].apply(
    lambda components: sum([1 for c in components if risk_dict.get(c, 'Low/Medium') == 'High'])
)

# Average component cost from suppliers
avg_component_cost = supplier_bom.groupby('ComponentID')['Cost ($)'].mean().to_dict()

# Calculate BuildCost per product (sum of component costs)
product_risk['BuildCost'] = product_risk['ComponentID'].apply(
    lambda comps: sum([avg_component_cost.get(c, 0) for c in comps])
)

# Add sales price
product_risk = pd.merge(product_risk, products[['ProductID', 'Sales Price ($)']], on='ProductID', how='left')

# Calculate profit
product_risk['ProfitPerUnit'] = product_risk['Sales Price ($)'] - product_risk['BuildCost']

# View result
product_risk[['ProductID', 'BuildCost', 'Sales Price ($)', 'ProfitPerUnit']].head()

print(products.columns)

# Check actual column name (update if needed)
price_column = 'Sales Price ($)'  # Change if the column name is different in your case

# Merge product price into product_risk
product_risk = pd.merge(
    product_risk,
    products[['ProductID', price_column]],
    on='ProductID',
    how='left'
)

# Now calculate ProfitPerUnit
product_risk['ProfitPerUnit'] = product_risk[price_column] - product_risk['BuildCost']

# Preview
product_risk[['ProductID', 'BuildCost', price_column, 'ProfitPerUnit']].head()

print(products.columns)

# Features to predict ProfitPerUnit
profit_features = ['ForecastedDemand', 'ActualDemand', 'BuildCost', 'AvgLeadTime', 'NumComponents']
X_profit = product_risk[profit_features]
y_profit = product_risk['ProfitPerUnit']

from sklearn.model_selection import train_test_split

X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X_profit, y_profit, test_size=0.3, random_state=42)

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

profit_model = LinearRegression()
profit_model.fit(X_train_p, y_train_p)
y_pred_p = profit_model.predict(X_test_p)

print("📈 Profit Prediction - Linear Regression")
print("MSE:", mean_squared_error(y_test_p, y_pred_p))
print("R2 Score:", r2_score(y_test_p, y_pred_p))

import matplotlib.pyplot as plt

plt.figure(figsize=(8, 5))
plt.plot(y_test_p.values[:20], label='Actual Profit')
plt.plot(y_pred_p[:20], label='Predicted Profit')
plt.title("Actual vs Predicted Profit per Unit (Sample)")
plt.xlabel("Sample Index")
plt.ylabel("Profit ($)")
plt.legend()
plt.show()

forecast_summary.to_csv("forecast_accuracy_summary.csv", index=False)

# Remove long lists like ComponentID before saving (optional)
product_risk_export = product_risk.drop(columns=['ComponentID'], errors='ignore')

product_risk_export.to_csv("product_risk_summary.csv", index=False)

supplier_summary.to_csv("supplier_risk_summary.csv", index=False)

profit_eval = pd.DataFrame({
    'ActualProfit': y_test_p.values,
    'PredictedProfit': y_pred_p
})
profit_eval.to_csv("predicted_vs_actual_profit.csv", index=False)

demand_eval = pd.DataFrame({
    'ActualDemand': y_test_xgb.values,
    'XGBoostForecast': y_pred_xgb
})
demand_eval.to_csv("predicted_vs_actual_demand.csv", index=False)

shortage_eval = pd.DataFrame({
    'ActualShortage': y_test.values,
    'PredictedShortage': y_pred_xgb  # or y_pred_rf / y_pred_lr
})
shortage_eval.to_csv("predicted_vs_actual_shortage.csv", index=False)

print("Length of y_test:", len(y_test))
print("Length of y_pred_xgb:", len(y_pred_xgb))

y_pred_xgb = xgb_model.predict(X_test)  # for shortage classification

import xgboost as xgb

# Re-train shortage risk XGBoost classifier
xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')
xgb_model.fit(X_train, y_train)

# Generate predictions
y_pred_xgb = xgb_model.predict(X_test)

# Confirm matching lengths
print(len(y_test), len(y_pred_xgb))  # should be equal

# Create the DataFrame
shortage_eval = pd.DataFrame({
    'ActualShortage': y_test.values,
    'PredictedShortage': y_pred_xgb
})

# Export as CSV
shortage_eval.to_csv("predicted_vs_actual_shortage.csv", index=False)

from google.colab import files
files.download("predicted_vs_actual_shortage.csv")
from google.colab import files

files.download("forecast_accuracy_summary.csv")
files.download("product_risk_summary.csv")
files.download("supplier_risk_summary.csv")
files.download("predicted_vs_actual_profit.csv")
files.download("predicted_vs_actual_demand.csv")
files.download("predicted_vs_actual_shortage.csv")

print("📊 Forecast Accuracy Summary (Top 5 Products)")
forecast_summary.sort_values(by='forecast_accuracy_%', ascending=False).head()

print("⚠️ Product Risk Summary (Top 5 by Shortage Risk + Low Inventory)")
product_risk[['ProductID', 'ForecastedDemand', 'TotalComponentOnHand', 'BuildCost', 'ProfitPerUnit', 'shortage_within_4w']].sort_values(by='TotalComponentOnHand').head()

print("🚨 Supplier Risk Summary (Top 5 Components with Few Suppliers + High Lead Time)")
supplier_summary.sort_values(by=['NumSuppliers', 'AvgLeadTime'], ascending=[True, False]).head()

print("💰 Profit Prediction (Actual vs Predicted - Sample 5)")
profit_eval = pd.DataFrame({
    'ActualProfit': y_test_p.values,
    'PredictedProfit': y_pred_p
})
profit_eval.head()

print("🔮 Shortage Prediction (Actual vs Predicted - Sample 5)")
shortage_eval = pd.DataFrame({
    'ActualShortage': y_test.values,
    'PredictedShortage': y_pred_xgb
})
shortage_eval.head()

plt.figure(figsize=(8, 5))
plt.plot(y_test_p.values[:20], label='Actual Profit')
plt.plot(y_pred_p[:20], label='Predicted Profit')
plt.title("📈 Actual vs Predicted Profit per Unit (First 20)")
plt.xlabel("Sample Index")
plt.ylabel("Profit ($)")
plt.legend()
plt.show()